{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.join(os.environ[\"BLACK_BOX\"])\n",
    "evals_path = os.path.join(parent_directory, \"experiments/results/evaluation_statistics\")\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from experiments.utils.validation_utils import load_eval_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Trained Agent Model Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation RL model folders located in ./experiments/results/evaluation_statistics folder\n",
    "folder_name_1 = \"evaluation_PPOTrainer_highway_environment:highway-environment-v0_2022-08-07_21-22-18mdgw9lf4_Agent0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Files In the Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_directory_1 = os.path.join(evals_path, folder_name_1)\n",
    "episode_evals_results_1 = [eval_directory_1 + \"/\" + f for f in os.listdir(eval_directory_1) if os.path.isfile(os.path.join(eval_directory_1, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return All Statistics for Each Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_eps_results = []\n",
    "eps_rewards = []\n",
    "\n",
    "for eps_stat in episode_evals_results_1:\n",
    "    \n",
    "    stat_df = load_eval_from_csv(file_name=eps_stat)\n",
    "    full_eps_results.append(stat_df)\n",
    "    \n",
    "    eps_avg_reward = stat_df[\"ego_rewards\"].mean(skipna = True)\n",
    "    eps_rewards.append(eps_avg_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = eps_rewards\n",
    "x_values = list(range(1, len(y_values) + 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Average Episode Reward - Evaluation\")\n",
    "plt.plot(x_values, y_values, color=\"red\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b77aff7649ba2a81292c27d8b3803e78308c619fc31255c3f8cb38deef8e8c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
