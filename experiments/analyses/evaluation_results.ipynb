{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.join(os.environ[\"BLACK_BOX\"])\n",
    "evals_path = os.path.join(parent_directory, \"experiments/results/evaluation_statistics\")\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from experiments.utils.validation_utils import load_eval_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Trained Agent Model Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation RL model folders located in ./experiments/results/evaluation_statistics folder\n",
    "folder_name_1 = \"evaluation_PPOTrainer_highway_environment:highway-environment-v0_2022-08-07_21-22-18mdgw9lf4_Agent0\"\n",
    "folder_name_2 = \"evaluation_PPOTrainer_highway_environment:highway-environment-v0_2022-08-19_19-34-16_a2cqydg_Agent1\"\n",
    "folder_name_3 = \"evaluation_PPOTrainer_highway_environment:highway-environment-v0_2022-08-19_23-31-04_y6fkw_8_Agent2\"\n",
    "folder_name_4 = \"evaluation_PPOTrainer_highway_environment:highway-environment-v0_2022-08-20_09-14-16_3_zp7wz_Agent3\"\n",
    "folder_name_5 = \"evaluation_PPOTrainer_highway_environment:highway-environment-v0_2022-08-08_09-45-04y_mw9iyt_Agent0123\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Files In the Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_directory_1 = os.path.join(evals_path, folder_name_1)\n",
    "eval_directory_2 = os.path.join(evals_path, folder_name_2)\n",
    "eval_directory_3 = os.path.join(evals_path, folder_name_3)\n",
    "eval_directory_4 = os.path.join(evals_path, folder_name_4)\n",
    "eval_directory_5 = os.path.join(evals_path, folder_name_5)\n",
    "\n",
    "episode_evals_results_1 = [eval_directory_1 + \"/\" + f for f in os.listdir(eval_directory_1) if os.path.isfile(os.path.join(eval_directory_1, f))]\n",
    "episode_evals_results_2 = [eval_directory_2 + \"/\" + f for f in os.listdir(eval_directory_2) if os.path.isfile(os.path.join(eval_directory_2, f))]\n",
    "episode_evals_results_3 = [eval_directory_3 + \"/\" + f for f in os.listdir(eval_directory_3) if os.path.isfile(os.path.join(eval_directory_3, f))]\n",
    "episode_evals_results_4 = [eval_directory_4 + \"/\" + f for f in os.listdir(eval_directory_4) if os.path.isfile(os.path.join(eval_directory_4, f))]\n",
    "episode_evals_results_5 = [eval_directory_5 + \"/\" + f for f in os.listdir(eval_directory_5) if os.path.isfile(os.path.join(eval_directory_5, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return All Statistics for Each Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(episode_evals_results):\n",
    "    full_eps_results = []\n",
    "    eps_rewards = []\n",
    "    n_collisions = []\n",
    "    n_impossibles = []\n",
    "\n",
    "    for eps_stat in episode_evals_results:\n",
    "\n",
    "        stat_df = load_eval_from_csv(file_name=eps_stat)\n",
    "        full_eps_results.append(stat_df)\n",
    "\n",
    "        eps_avg_reward = stat_df[\"ego_rewards\"].mean(skipna = True)\n",
    "        eps_sum_reward = stat_df[\"ego_rewards\"].sum(skipna = True)\n",
    "        eps_rewards.append(eps_sum_reward)\n",
    "\n",
    "        is_collision = stat_df[\"is_collision\"].iloc[0]\n",
    "        n_collisions.append(is_collision)\n",
    "\n",
    "        is_impossible = stat_df[\"is_impossible\"].iloc[0]\n",
    "        n_impossibles.append(is_impossible)\n",
    "    \n",
    "    return full_eps_results, eps_rewards, n_collisions, n_impossibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), \"full\") / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_eps_results_1, eps_rewards_1, n_collisions_1, n_impossibles_1 = get_stats(episode_evals_results_1)\n",
    "full_eps_results_2, eps_rewards_2, n_collisions_2, n_impossibles_2 = get_stats(episode_evals_results_2)\n",
    "full_eps_results_3, eps_rewards_3, n_collisions_3, n_impossibles_3 = get_stats(episode_evals_results_3)\n",
    "full_eps_results_4, eps_rewards_4, n_collisions_4, n_impossibles_4 = get_stats(episode_evals_results_4)\n",
    "full_eps_results_5, eps_rewards_5, n_collisions_5, n_impossibles_5 = get_stats(episode_evals_results_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values_1 = eps_rewards_1\n",
    "y_values_2 = eps_rewards_2\n",
    "y_values_3 = eps_rewards_3\n",
    "y_values_4 = eps_rewards_4\n",
    "y_values_5 = eps_rewards_5\n",
    "\n",
    "x_values = list(range(1, len(y_values_1) + 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Evaluation Episode Reward\")\n",
    "\n",
    "plt.plot(x_values, y_values_1, color=\"red\")\n",
    "plt.plot(x_values, y_values_2, color=\"green\")\n",
    "plt.plot(x_values, y_values_3, color=\"blue\")\n",
    "plt.plot(x_values, y_values_4, color=\"yellow\")\n",
    "plt.plot(x_values, y_values_5, color=\"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_moving_avg_1 = moving_average(np.array(y_values_1), 20)\n",
    "y_moving_avg_2 = moving_average(np.array(y_values_2), 20)\n",
    "y_moving_avg_3 = moving_average(np.array(y_values_3), 20)\n",
    "y_moving_avg_4 = moving_average(np.array(y_values_4), 20)\n",
    "y_moving_avg_5 = moving_average(np.array(y_values_5), 20)\n",
    "\n",
    "x_moving_values = list(range(1, len(y_moving_avg_1) + 1, 1))\n",
    "\n",
    "plt.title(\"Evaluation Moving Average Episode Reward\")\n",
    "plt.plot(x_moving_values, y_moving_avg_1, color=\"red\", label=\"Agent-0\")\n",
    "plt.plot(x_moving_values, y_moving_avg_2, color=\"green\", label=\"Agent-1\")\n",
    "plt.plot(x_moving_values, y_moving_avg_3, color=\"blue\", label=\"Agent-2\")\n",
    "plt.plot(x_moving_values, y_moving_avg_4, color=\"yellow\", label=\"Agent-3\")\n",
    "plt.plot(x_moving_values, y_moving_avg_5, color=\"black\", label=\"Agent-Vanilla\")\n",
    "\n",
    "text = \"Agent-0 Collisions : \" + str(n_collisions_1.count(True)) \\\n",
    "        + \"\\n\\nAgent-1 Collisions : \" + str(n_collisions_2.count(True)) \\\n",
    "        + \"\\n\\nAgent-2 Collisions : \" + str(n_collisions_3.count(True)) \\\n",
    "        + \"\\n\\nAgent-3 Collisions : \" + str(n_collisions_4.count(True)) \\\n",
    "        + \"\\n\\nAgent-Vanilla Collisions : \" + str(n_collisions_5.count(True))\n",
    "\n",
    "plt.text(1100, 28, text)\n",
    "\n",
    "plt.xlabel(\"Number of Scenarios\")\n",
    "plt.ylabel(\"Running Average Episode Reward\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "save_name = \"running_reward\"\n",
    "plt.savefig(save_name + \".jpg\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b77aff7649ba2a81292c27d8b3803e78308c619fc31255c3f8cb38deef8e8c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
